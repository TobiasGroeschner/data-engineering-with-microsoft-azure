{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark SQL Quiz\n",
    "\n",
    "This quiz uses the same dataset and most of the same questions from the earlier \"Quiz - Data Wrangling with Data Frames Jupyter Notebook.\" For this quiz, however, use Spark SQL instead of Spark Data Frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# TODOS: \n",
    "# 1) import any other libraries you might need\n",
    "\n",
    "\n",
    "# 2) instantiate a Spark session \n",
    "# 3) read in the data set located at the path \"data/sparkify_log_small.json\"\n",
    "# 4) create a view to use with your SQL queries\n",
    "# 5) write code to answer the quiz questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Data wrangling with Spark SQL\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.createOrReplaceTempView(\"user_log_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\"(empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write your code to answer question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| page|\n",
      "+-----+\n",
      "| Home|\n",
      "|About|\n",
      "|Login|\n",
      "| Help|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT DISTINCT page\n",
    "          FROM user_log_table \n",
    "          WHERE userId == \"\"\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the pages `userId == \"\"`visited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            page|\n",
      "+----------------+\n",
      "|Submit Downgrade|\n",
      "|            Home|\n",
      "|       Downgrade|\n",
      "|          Logout|\n",
      "|   Save Settings|\n",
      "|           About|\n",
      "|        Settings|\n",
      "|           Login|\n",
      "|        NextSong|\n",
      "|            Help|\n",
      "|         Upgrade|\n",
      "|           Error|\n",
      "|  Submit Upgrade|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT DISTINCT page FROM user_log_table\n",
    "          '''\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all the pages present. So we have to perform a right join to see all the pages userId == \"\" did not visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+\n",
      "| page|            page|\n",
      "+-----+----------------+\n",
      "| null|Submit Downgrade|\n",
      "| Home|            Home|\n",
      "| null|       Downgrade|\n",
      "| null|          Logout|\n",
      "| null|   Save Settings|\n",
      "|About|           About|\n",
      "| null|        Settings|\n",
      "|Login|           Login|\n",
      "| null|        NextSong|\n",
      "| Help|            Help|\n",
      "| null|         Upgrade|\n",
      "| null|           Error|\n",
      "| null|  Submit Upgrade|\n",
      "+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "         SELECT * FROM\n",
    "          (SELECT DISTINCT page\n",
    "          FROM user_log_table \n",
    "          WHERE userId == \"\") AS user_pages\n",
    "          RIGHT JOIN (SELECT DISTINCT page FROM user_log_table) AS all_pages\n",
    "          ON user_pages.page =  all_pages.page\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefer Spark SQL:\n",
    "\n",
    "- **SQL Expertise**: its easier\n",
    "\n",
    "- **Existing SQL Codebase**: If you have existing SQL code or are transitioning from a traditional relational database environment, using Spark SQL can make it easier to reuse and adapt your SQL queries for big data processing.\n",
    "\n",
    "\n",
    "Prefer Spark DataFrames:\n",
    "\n",
    "- **Expressiveness and Flexibility**: Spark DataFrames provide a more expressive and flexible API for data manipulation using a syntax similar to pandas or R data frames. This is especially useful for complex data transformations and analysis.\n",
    "\n",
    "\n",
    "- **Performance**: While Spark SQL and DataFrames are closely integrated, in some cases, expressing your logic using the DataFrame API directly may provide more control and better performance for certain operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write your code to answer question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|userId|gender|\n",
      "+------+------+\n",
      "|  2902|     F|\n",
      "|  1872|     M|\n",
      "|   838|     F|\n",
      "|   314|     M|\n",
      "|  1941|     M|\n",
      "|  1545|     M|\n",
      "|   577|     F|\n",
      "|  2122|     F|\n",
      "|  2049|     M|\n",
      "|  2967|     M|\n",
      "|  1887|     F|\n",
      "|  1661|     F|\n",
      "|  1403|     M|\n",
      "|  2546|     F|\n",
      "|  1866|     F|\n",
      "|  1162|     F|\n",
      "|  1232|     M|\n",
      "|  2675|     F|\n",
      "|  1865|     M|\n",
      "|  2933|     M|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "         SELECT \n",
    "             distinct userId,\n",
    "             gender\n",
    "         FROM user_log_table\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|  2904|\n",
      "|   691|\n",
      "|  2294|\n",
      "|  2162|\n",
      "|  1436|\n",
      "|  2088|\n",
      "|  2275|\n",
      "|  2756|\n",
      "|   800|\n",
      "|  1394|\n",
      "|   451|\n",
      "|   926|\n",
      "|  1746|\n",
      "|  2696|\n",
      "|  1280|\n",
      "|   870|\n",
      "|     7|\n",
      "|  1903|\n",
      "|   591|\n",
      "|   613|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT distinct userId\n",
    "          FROM user_log_table\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(gender)|\n",
      "+-------------+\n",
      "|          462|\n",
      "|            0|\n",
      "|          501|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "         SELECT count(gender)\n",
    "         FROM (SELECT distinct userId, gender FROM user_log_table)\n",
    "         GROUP BY gender\n",
    "         '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|              artist|count(artist)|\n",
      "+--------------------+-------------+\n",
      "|            Coldplay|           83|\n",
      "|       Kings Of Leon|           69|\n",
      "|Florence + The Ma...|           52|\n",
      "|            BjÃÂ¶rk|           46|\n",
      "|       Dwight Yoakam|           45|\n",
      "|       Justin Bieber|           43|\n",
      "|      The Black Keys|           40|\n",
      "|         OneRepublic|           37|\n",
      "|                Muse|           36|\n",
      "|        Jack Johnson|           36|\n",
      "|           Radiohead|           31|\n",
      "|        Taylor Swift|           29|\n",
      "|               Train|           28|\n",
      "|Barry Tuckwell/Ac...|           28|\n",
      "|          Lily Allen|           28|\n",
      "|          Nickelback|           27|\n",
      "|           Metallica|           27|\n",
      "|           Daft Punk|           27|\n",
      "|          Kanye West|           26|\n",
      "|Red Hot Chili Pep...|           24|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 4\n",
    "\n",
    "spark.sql('''\n",
    "         SELECT artist, count(artist)\n",
    "         FROM user_log_table\n",
    "         GROUP BY artist\n",
    "         ORDER BY count(song) DESC\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was not able to solve it, looked at the solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT CASE WHEN 1 > 0 THEN 1 WHEN 2 > 0 THEN 2.0 ELSE 1.2 END;\n",
    "is_home = spark.sql(\n",
    "            '''\n",
    "            SELECT \n",
    "                userID, \n",
    "                page, \n",
    "                ts, \n",
    "                CASE \n",
    "                    WHEN page = 'Home' \n",
    "                        THEN 1\n",
    "                        ELSE 0 \n",
    "                END AS is_home \n",
    "            FROM user_log_table \n",
    "            WHERE (page = 'NextSong') or (page = 'Home') \n",
    "            ''')\n",
    "\n",
    "\n",
    "# keep the results in a new view\n",
    "is_home.createOrReplaceTempView(\"is_home_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+-------+\n",
      "|userID|    page|           ts|is_home|\n",
      "+------+--------+-------------+-------+\n",
      "|  1046|NextSong|1513720872284|      0|\n",
      "|  1000|NextSong|1513720878284|      0|\n",
      "|  2219|NextSong|1513720881284|      0|\n",
      "|  2373|NextSong|1513720905284|      0|\n",
      "|  1747|    Home|1513720913284|      1|\n",
      "|  1162|NextSong|1513720955284|      0|\n",
      "|  1061|NextSong|1513720959284|      0|\n",
      "|   748|    Home|1513720959284|      1|\n",
      "|   597|    Home|1513720980284|      1|\n",
      "|  1806|NextSong|1513720983284|      0|\n",
      "|   748|NextSong|1513720993284|      0|\n",
      "|  1176|NextSong|1513721031284|      0|\n",
      "|  2164|NextSong|1513721045284|      0|\n",
      "|  2146|NextSong|1513721058284|      0|\n",
      "|  2219|NextSong|1513721077284|      0|\n",
      "|  1176|    Home|1513721088284|      1|\n",
      "|  2904|NextSong|1513721095284|      0|\n",
      "|   597|NextSong|1513721097284|      0|\n",
      "|   226|NextSong|1513721104284|      0|\n",
      "|  1046|NextSong|1513721104284|      0|\n",
      "+------+--------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_home.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the cumulative sum over the is_home column\n",
    "cumulative_sum = spark.sql(\n",
    "        '''\n",
    "        SELECT *, SUM(is_home) OVER\n",
    "        (PARTITION BY userID \n",
    "        ORDER BY ts DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS period\n",
    "        FROM is_home_table\n",
    "        '''\n",
    "        )\n",
    "\n",
    "\n",
    "# keep the results in a view\n",
    "cumulative_sum.createOrReplaceTempView(\"period_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(count_results)|\n",
      "+------------------+\n",
      "| 6.898347107438017|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the average count for NextSong\n",
    "spark.sql('''\n",
    "          SELECT AVG(count_results) FROM \n",
    "          (SELECT COUNT(*) AS count_results FROM period_table \n",
    "          GROUP BY userID, period, page HAVING page = 'NextSong') AS counts\n",
    "''').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
